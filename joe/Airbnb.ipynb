{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airpy.agd import * # age+gender predict data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check, pre_age = pre_age_set_data(train_users_2, test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_gen_mission_test, pre_gen_train_test, pre_gen_mission, pre_gen_train, \\\n",
    "            pre_gen_mission_test_drop, pre_gen_train_test_drop = pre_gen_predict_data(pre_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen_lgb = predict_gen_LightGBM(pre_gen_train_test_drop, pre_gen_train_test, pre_gen_train_test_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen_lgb.to_csv(\"model_gen_lgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_age_mission_test, pre_age_train_test, pre_age_mission, pre_age_train, \\\n",
    "            pre_age_mission_test_drop, pre_age_train_test_drop = pre_age_predict_data(pre_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = pre_age_predict_data_cat(pre_age_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_age_lgb = predict_age_LightGBM(pre_age_train_test_drop, cats, pre_age_mission_test_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_age_lgb.to_csv(\"model_age_lgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airpy.merge import * # sessions merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sessions = make_merged_sessions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sessions = remove_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sessions = sessions_detail_add()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airpy.data import * # classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check, pre_age = pre_age_set_data(train_users_2, test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_age_mission_test, pre_age_train_test, pre_age_mission, pre_age_train, \\\n",
    "            pre_age_mission_test_drop, pre_age_train_test_drop = pre_age_predict_data(pre_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = pre_age_predict_data_cat(pre_age_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_gen_add = add_gender(pre_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_hol = holiday(train_users_2, test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_data, last_test_data, y_label, le = predict_age_add(pre_age_mission_test, pre_age_train_test, last_gen_add, add_hol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_data_add, last_test_data_add = last_data_setting(last_train_data, last_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project : Airbnb New User Booking\n",
    "---\n",
    "\n",
    "### Abstract :  \n",
    "\n",
    "- purpose of prediction\n",
    "\n",
    "- Model\n",
    "\n",
    "- Score\n",
    "\n",
    "\n",
    "### Introduction :\n",
    "\n",
    "- purpose of analysis : Predict destination country\n",
    "\n",
    "- evaluation metric : NDCG (Normalized discounted cumulative gain)\n",
    "\n",
    "- evaluation question : \n",
    "\n",
    "\n",
    "### Methods :\n",
    "\n",
    "- Description of selected model :\n",
    "\n",
    "- comparision of selected model and other method :\n",
    "\n",
    "- feature engineering : \n",
    "\n",
    "        - train / test missing data : \n",
    "        \n",
    "        - train / test categorical data :\n",
    "        \n",
    "        - sessions :\n",
    "        \n",
    "        - dropped data : age bkts, countries\n",
    "\n",
    "### Conclusions :\n",
    "\n",
    "##### A. Summary of Key Findings:\n",
    "\n",
    "##### B. Final Analysis :\n",
    "- * How does the author understand the data\n",
    "- * How does the author believe the data will impact the program\n",
    "- * Strengths and weaknesses of the program as revealed by evaluation findings \n",
    "\n",
    "##### C. Issues for Further Consideration (any outstanding issues raised by the evaluation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction :\n",
    "\n",
    "- purpose of analysis : Predict destination country\n",
    "\n",
    "- evaluation metric : NDCG (Normalized discounted cumulative gain)\n",
    "\n",
    "\n",
    "$$\n",
    "DCG_k=\\sum_{i=1}^k\\frac{2^{rel_i}-1}{\\log_2{\\left(i+1\\right)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "nDCG_k=\\frac{DCG_k}{IDCG_k}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods :\n",
    "\n",
    "- Description of selected model :\n",
    "\n",
    "- comparision of selected model and other method :\n",
    "\n",
    "- feature engineering : \n",
    "\n",
    "        - train / test missing data : \n",
    "                \n",
    "                - date_first_booking : dropped\n",
    "                \n",
    "                - age : filled by clustering age buckets\n",
    "                \n",
    "                - first_affiliate_tracked : filled by mode data\n",
    "        \n",
    "        - train / test categorical data : \n",
    "        \n",
    "                - one-hot encoding\n",
    "        \n",
    "        - sessions :\n",
    "        \n",
    "                - action\n",
    "                \n",
    "                - action type\n",
    "                \n",
    "                - secs elapsed time\n",
    "        \n",
    "        - other features :\n",
    "        \n",
    "                - etc\n",
    "                \n",
    "                - etc\n",
    "        \n",
    "        - dropped data : age bkts, countries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_users_2.csv\")\n",
    "df_test = pd.read_csv(\"test_users.csv\")\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "df_countries = pd.read_csv('countries.csv')\n",
    "df_sessions = pd.read_csv('sessions.csv')\n",
    "df_age_bkts = pd.read_csv('age_gender_bkts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.drop(\"country_destination\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.isnull().sum().sort_values(ascending = False).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing data ratio')\n",
    "print('date_frist_booking :',round(df_all.date_first_booking.isnull().sum() / len(df_all) * 100, 2))\n",
    "print('age :',round(df_all.age.isnull().sum() / len(df_all) * 100, 2))\n",
    "print('first_affiliate_tracked:',round(df_all.first_affiliate_tracked.isnull().sum() / len(df_all) * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Explore Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df_train[\"country_destination\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df_train[\"country_destination\"].value_counts() / len(df_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Impute featrues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-1. Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df_all[\"gender\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- female - male "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"count\"] = 1\n",
    "df_gender_country = df_train.pivot_table(values = \"count\", index = [\"country_destination\"], columns = [\"gender\"], aggfunc=np.sum)\n",
    "df_gender_country[\"FEMALE\"] = df_gender_country[\"FEMALE\"] / df_gender_country[\"FEMALE\"].sum() * 100\n",
    "df_gender_country[\"MALE\"] = df_gender_country[\"MALE\"] / df_gender_country[\"MALE\"].sum() * 100\n",
    "(df_gender_country[\"FEMALE\"] - df_gender_country[\"MALE\"]).sort_values(ascending = False).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여자는 FR, IT 주로 여행을 간다. \n",
    "- 남자는 DE, other를 주로 여행을 간다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-2. Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"0:0-27\", \"1:27-31\", \"2:31-36\", \"3:36-46\", \"4:46-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"age_cut\"] = pd.qcut(df_train[df_train[\"age\"] <= 120]['age'], 5, labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_pivot = df_train.pivot_table(values = \"count\", index = \"age_cut\", columns = \"country_destination\", aggfunc = np.sum, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df_age_pivot.index:\n",
    "    df_age_pivot.loc[c] = (df_age_pivot.loc[c] / (df_train[\"age_cut\"] == c).sum() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_pivot.T.plot(kind = \"bar\", figsize = (20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_age_pivot.T.plot(kind = \"bar\", figsize = (20, 5))\n",
    "plt.ylim([0,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NDF : 27-36세는 NDF가 아닐 확률이 높다.\n",
    "- US  : 27-36세는 US로 여행할 확률이 높다.\n",
    "- FR  : 나이가 늘어 날수록 여행갈 비율이 높다.\n",
    "- other : 27-36세는 other에 여행할 확률이 약간 높다.\n",
    "- GB  : 46-세는 GB에 여행갈 확률이 높다\n",
    "- ES  : 0-27세는 ES에 여행갈 확률이 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-3. first_affiliate_tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df_all[\"first_affiliate_tracked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"first_affiliate_tracked\"].value_counts() / len(df_all) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 특징에서 51.96%가 untracked이기 때문에 최빈값 `untracked` 으로 Missing value 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code\n",
    "df_train[\"first_affiliate_tracked\"].fillna(\"untracked\")\n",
    "df_test[\"first_affiliate_tracked\"].fillna(\"untracked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-4. date_first_booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_exist = len(df_test) - df_test[\"date_first_booking\"].isnull().sum()\n",
    "print(\"Number of date_first_booking in test : {}\".format(test_exist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test 데이터에는 date_first_booking 특징이 전혀 존재하지 않기 때문에 해당 특지은 사용하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code\n",
    "df_train.drop(\"date_first_booking\", axis = 1, inplace = True)\n",
    "df_test.drop(\"date_first_booking\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Create featrues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-1. Faithless sign-in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **가정) 가입을 꼼꼼하게 한 사람일수록 여행을 예약할 확률이 높다** \n",
    "\n",
    "  - `age`가 `nan`이거나 `이상값`이거나 `gender`가 `unknown`일 경우, 가입을 대충했다고 가정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_all_input_train = (df_train['age'] < 120) & (df_train['gender'] != '-unknown-')\n",
    "s_all_input_test = (df_test['age'] < 120) & (df_test['gender'] != '-unknown-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['faithless_sign'] = s_all_input_train.apply(lambda x : 0 if x == True else 1)\n",
    "df_test['faithless_sign'] = s_all_input_test.apply(lambda x : 0 if x == True else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-2. Session info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **가정) 사이트를 자주 들어간 사람일수록 여행을 예약할 확률이 높다**\n",
    "  - 각 `user_id`별 session count 갯수가 많을 수록, 사이트를 자주 들어 왔다고 가정\n",
    "- **추가 사항 : secs_elapse_mean, secs_elapse_mode, secs_elapse_sum, device_type_mode**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### action, action_type, action_detail count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make action count\n",
    "tmp = df_session.groupby([\"user_id\", \"action_type\"])[\"secs_elapsed\"].count().unstack().fillna(0)\n",
    "df_session_type = pd.DataFrame(tmp)\n",
    "df_session_type.rename(columns = lambda x : \"type_\" + x, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make action_type count\n",
    "tmp = df_session.groupby([\"user_id\", \"action\"])[\"secs_elapsed\"].count().unstack().fillna(0)\n",
    "df_session_action = pd.DataFrame(tmp)\n",
    "df_session_action.rename(columns = lambda x : \"action_\" + x, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make action_detail count\n",
    "tmp = df_session.groupby([\"user_id\", \"action_detail\"])[\"secs_elapsed\"].count().unstack().fillna(0)\n",
    "df_session_action_detail = pd.DataFrame(tmp)\n",
    "df_session_action_detail.rename(columns = lambda x : \"detail_\" + x, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session_info = df_session_type.merge(df_session_action, how = \"left\", left_index = True, right_index = True)\n",
    "df_session_info = df_session_info.merge(df_session_action_detail, how = \"left\", left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop unknown value\n",
    "df_session_info.drop([\"type_-unknown-\", \"detail_-unknown-\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## impute the missing value using median\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "df_train = df_train_origin.merge(df_session_info, how = \"left\", left_on = \"id\", right_index = True)\n",
    "df_test = df_test_origin.merge(df_session_info, how = \"left\", left_on = \"id\", right_index = True)\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "\n",
    "df_train[df_session_info.columns.tolist()] = imp.fit_transform(df_train[df_session_info.columns.tolist()])\n",
    "df_test[df_session_info.columns.tolist()] = imp.fit_transform(df_test[df_session_info.columns.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-3. Date info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **가정1) 주말에 처음 활동한 사람일수록 여행을 예약할 확률이 높다** \n",
    "- **가정2) 공휴일에 처음 활동한 사람일수록 여행을 예약할 확률이 높다**\n",
    "- **추가 사항 : first_active_year, first_active_month, first_active_day, first_active_weekend, create_account_year, create_account_month, create_account_day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holidays(year):\n",
    "    response = requests.get(\"https://www.timeanddate.com/calendar/custom.html?year=\"+str(year)+\"\\\n",
    "                            &country=1&cols=3&df=1&hol=25\")\n",
    "    dom = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    trs = dom.select(\"table.cht.lpad tr\")\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"date\", \"holiday\"])\n",
    "    for tr in trs:\n",
    "        datestr = tr.select_one(\"td:nth-of-type(1)\").text\n",
    "        date = datetime.strptime(\"{} {}\".format(year, datestr), '%Y %b %d')\n",
    "        holiday = tr.select_one(\"td:nth-of-type(2)\").text\n",
    "        df.loc[len(df)] = {\"date\" : date, \"holiday\": 1}\n",
    "    return df\n",
    "\n",
    "holiday_ls = []\n",
    "for year in range(2009, 2015):\n",
    "    df = get_holidays(year)\n",
    "    holiday_ls.append(df)\n",
    "    holiday_df = pd.concat(holiday_ls)\n",
    "\n",
    "check = pd.concat([train_users_2, test_users], ignore_index=True)\n",
    "check[\"timestamp_first_active\"] = check[\"timestamp_first_active\"].apply(lambda x : str(x)[:8])\n",
    "\n",
    "pre_age_hol = check.filter(items=['id','timestamp_first_active'])\n",
    "\n",
    "pre_age_hol['week'] = pd.to_datetime(check[\"timestamp_first_active\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "pre_age_hol[\"week\"] = pre_age_hol['week'].dt.weekday\n",
    "pre_age_hol[\"weekend\"] = pre_age_hol[\"week\"].apply(lambda x : 1 if x>=5 else 0)\n",
    "pre_age_hol_dum = pd.get_dummies(pre_age_hol['week'])\n",
    "\n",
    "hdfd = pd.concat([pre_age_hol,pre_age_hol_dum],axis=1)\n",
    "hdfd = hdfd.drop(\"week\",axis=1)\n",
    "\n",
    "hdfd = hdfd.rename(columns={0:\"mon\",1:\"tue\",2:\"wed\",3:\"thur\",4:\"fri\",5:\"sat\",6:\"sun\"})\n",
    "\n",
    "hdfd['timestamp_first_active'] = pd.to_datetime(hdfd[\"timestamp_first_active\"])\n",
    "\n",
    "add_hol = pd.merge(hdfd, holiday_df, left_on='timestamp_first_active', right_on=\"date\", how=\"left\")\n",
    "\n",
    "add_hol = add_hol.drop([\"timestamp_first_active\",'date'],axis=1)\n",
    "add_hol = add_hol.fillna(0)\n",
    "add_hol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-4. Lag-time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **가정) 활동 빈도가 적을 수록 여행을 예약할 확률이 낮다**\n",
    "  - 처음으로 활동한 날짜 - 처음 계정을 생성한 날짜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"date_account_created\"] = pd.to_datetime(df_train[\"date_account_created\"], format = \"%Y-%m-%d\")\n",
    "df_train[\"timestamp_first_active\"] = pd.to_datetime(df_train[\"timestamp_first_active\"], format=\"%Y%m%d%H%M%S\", errors='ignore')\n",
    "df_test[\"date_account_created\"] = pd.to_datetime(df_test[\"date_account_created\"], format = \"%Y-%m-%d\")\n",
    "df_test[\"timestamp_first_active\"] = pd.to_datetime(df_test[\"timestamp_first_active\"], format=\"%Y%m%d%H%M%S\", errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_train_lag = df_train[\"timestamp_first_active\"] - df_train[\"date_account_created\"]\n",
    "s_test_lag = df_test[\"timestamp_first_active\"] - df_test[\"date_account_created\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"lag_days\"] = s_train_lag.apply(lambda x : -1 * x.days)\n",
    "df_test[\"lag_days\"] = s_test_lag.apply(lambda x : -1 * x.days)\n",
    "df_train[\"lag_seconds\"] = s_train_lag.apply(lambda x : x.seconds)\n",
    "df_test[\"lag_seconds\"] = s_test_lag.apply(lambda x : x.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Featrues selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1. Use importance feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Selection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Analysis the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_gender_bkts = pd.read_csv(\"age_gender_bkts.csv\")\n",
    "countries = pd.read_csv(\"countries.csv\")\n",
    "sessions = pd.read_csv(\"sessions.csv\")\n",
    "test_users = pd.read_csv(\"test_users.csv\")\n",
    "train_users_2 = pd.read_csv(\"train_users_2.csv\")\n",
    "sample_submission_NDF = pd.read_csv(\"sample_submission_NDF.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_age_set_data():\n",
    "    \n",
    "    check = pd.concat([train_users_2, test_users], ignore_index=True)\n",
    "    \n",
    "    check[\"first_affiliate_tracked\"] = check[\"first_affiliate_tracked\"].replace(np.nan, \"untracked\")\n",
    "    \n",
    "    check[\"date_account_created\"] = pd.to_datetime(check[\"date_account_created\"], format = \"%Y-%m-%d\")\n",
    "    check[\"timestamp_first_active\"] = pd.to_datetime(check[\"timestamp_first_active\"], format=\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    s_lag = check[\"timestamp_first_active\"] - check[\"date_account_created\"]\n",
    "\n",
    "    check[\"lag_days\"] = s_lag.apply(lambda x : -1 * x.days)\n",
    "    check[\"lag_seconds\"] = s_lag.apply(lambda x : x.seconds)\n",
    "\n",
    "    s_all_check = (check['age'] < 120) & (check['gender'] != '-unknown-')\n",
    "\n",
    "    check['faithless_sign'] = s_all_check.apply(lambda x : 0 if x == True else 1)\n",
    "    \n",
    "    pre_age = check.drop(\"date_first_booking\",axis = 1)\n",
    "    \n",
    "    pre_age['date_account_created_y'] = pre_age[\"date_account_created\"].apply(lambda x : x.year)\n",
    "    pre_age['date_account_created_m'] = pre_age[\"date_account_created\"].apply(lambda x : x.month)\n",
    "    pre_age['date_account_created_d'] = pre_age[\"date_account_created\"].apply(lambda x : x.day)\n",
    "\n",
    "    pre_age['timestamp_first_active_y'] = pre_age[\"timestamp_first_active\"].apply(lambda x : x.year)\n",
    "    pre_age['timestamp_first_active_m'] = pre_age[\"timestamp_first_active\"].apply(lambda x : x.month)\n",
    "    pre_age['timestamp_first_active_d'] = pre_age[\"timestamp_first_active\"].apply(lambda x : x.day)\n",
    "\n",
    "    pre_age = pre_age.drop(\"date_account_created\" , axis=1)\n",
    "    pre_age = pre_age.drop(\"timestamp_first_active\" , axis=1)\n",
    "    \n",
    "    return check, pre_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender predict data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_gen_predict_data():\n",
    "\n",
    "    pre_gen_sub = pre_age.filter(items = ['age', 'country_destination', 'id', 'gender'])\n",
    "    pre_gen_dum = pre_age.filter(items = ['affiliate_channel', 'affiliate_provider',\n",
    "                                       'first_affiliate_tracked', 'first_browser', 'first_device_type',\n",
    "                                         'language', 'signup_app', 'signup_flow',\n",
    "                                       'signup_method', 'date_account_created_y', 'date_account_created_m',\n",
    "                                       'date_account_created_d', 'timestamp_first_active_y',\n",
    "                                       'timestamp_first_active_m', 'timestamp_first_active_d'])\n",
    "\n",
    "\n",
    "    pre_gen_dum = pd.get_dummies(pre_gen_dum)\n",
    "    pre_gen_dum_con = pd.concat([pre_gen_dum, pre_gen_sub], axis=1)\n",
    "    pre_gen_dum_con[\"gender\"] = pre_gen_dum_con[\"gender\"].replace(['-unknown-', 'OTHER'], np.nan)\n",
    "\n",
    "    pre_gen_mission = pre_gen_dum_con[pre_gen_dum_con[\"gender\"].isna()].reset_index()\n",
    "    pre_gen_train = pre_gen_dum_con[pre_gen_dum_con[\"gender\"].notna()].reset_index()\n",
    "\n",
    "    pre_gen_mission_test = pre_gen_mission.drop(\"index\", axis=1)\n",
    "    pre_gen_train_test = pre_gen_train.drop(\"index\", axis=1)\n",
    "\n",
    "    pre_gen_mission_test_drop = pre_gen_mission_test.drop(['id', 'age', 'country_destination', \"gender\"], axis=1)\n",
    "    pre_gen_train_test_drop = pre_gen_train_test.drop(['id', 'age', 'country_destination', \"gender\"], axis=1)\n",
    "    \n",
    "    return pre_gen_mission_test, pre_gen_train_test, pre_gen_mission, pre_gen_train, \\\n",
    "            pre_gen_mission_test_drop, pre_gen_train_test_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender predict LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_gen_LightGBM():\n",
    "\n",
    "    X = pre_gen_train_test_drop\n",
    "    y = pre_gen_train_test[\"gender\"]\n",
    "    \n",
    "    model_gen_lgb = lgb.LGBMClassifier(nthread=3)\n",
    "    model_gen_lgb.fit(X,y)\n",
    "\n",
    "    print(classification_report(y, model_gen_lgb.predict(pre_gen_train_test_drop)))\n",
    "    model_gen_lgb = model_gen_lgb.predict(pre_gen_mission_test_drop)\n",
    "    model_gen_lgb = pd.DataFrame(model_gen_lgb)\n",
    "    \n",
    "    return model_gen_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender predict data make CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen_lgb.to_csv(\"model_gen_lgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age predict data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_age_predict_data():\n",
    "    \n",
    "    pre_age['age'] = pre_age['age'].fillna(-1)\n",
    "    \n",
    "    pre_age_sub = pre_age.filter(items = ['age', 'country_destination','id'])\n",
    "    pre_age_dum = pre_age.filter(items = ['affiliate_channel', 'affiliate_provider',\n",
    "                                       'first_affiliate_tracked', 'first_browser', 'first_device_type',\n",
    "                                       'language', 'signup_app', 'signup_flow',\n",
    "                                       'signup_method', 'date_account_created_y', 'date_account_created_m',\n",
    "                                       'date_account_created_d', 'timestamp_first_active_y',\n",
    "                                       'timestamp_first_active_m', 'timestamp_first_active_d'])\n",
    "    \n",
    "    pre_age_dum = pd.get_dummies(pre_age_dum)\n",
    "    pre_age_dum_con = pd.concat([pre_age_dum, pre_age_sub], axis=1)\n",
    "    pre_age_dum_con[\"age\"] = pre_age_dum_con[\"age\"].replace(-1, np.nan)\n",
    "    \n",
    "    pre_age_mission = pre_age_dum_con[pre_age_dum_con[\"age\"].isna()].reset_index()\n",
    "    pre_age_train = pre_age_dum_con[pre_age_dum_con[\"age\"].notna()].reset_index()\n",
    "    \n",
    "    pre_age_mission_test = pre_age_mission.drop(\"index\", axis=1)\n",
    "    pre_age_train_test = pre_age_train.drop(\"index\", axis=1)\n",
    "    \n",
    "    pre_age_mission_test_drop = pre_age_mission_test.drop(['id', 'age', 'country_destination'], axis=1)\n",
    "    pre_age_train_test_drop = pre_age_train_test.drop(['id', 'age', 'country_destination'], axis=1)\n",
    "    \n",
    "    return pre_age_mission_test, pre_age_train_test, pre_age_mission, pre_age_train, \\\n",
    "            pre_age_mission_test_drop, pre_age_train_test_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_age_predict_data_cat():\n",
    "    \n",
    "    bins = [0, 15, 25, 35, 60, 9999]\n",
    "    labels = [\"미성년자\", \"청년\", \"중년\", \"장년\", \"노년\"]\n",
    "    cats = pd.cut(pre_age_train['age'], bins, labels=labels)\n",
    "    cats = pd.DataFrame(cats)\n",
    "    \n",
    "    return cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age predict LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def predict_age_LightGBM():\n",
    "\n",
    "    X = pre_age_train_test_drop\n",
    "    y = cats\n",
    "    \n",
    "    model_age_lgb = lgb.LGBMClassifier(nthread=3)\n",
    "    model_age_lgb.fit(X,y)\n",
    "\n",
    "    print(classification_report(y, model_age_lgb.predict(pre_age_train_test_drop)))\n",
    "    model_age_lgb = model_age_lgb.predict(pre_age_mission_test_drop)\n",
    "    model_age_lgb = pd.DataFrame(model_age_lgb)\n",
    "    \n",
    "    return model_age_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age predict data make CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_age_lgb.to_csv(\"model_age_lgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sessions (groupby mode + secs_elapsed setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_merged_sessions():\n",
    "    \n",
    "    sessions = pd.read_csv(\"sessions.csv\")\n",
    "    \n",
    "    sessions[\"action\"] = sessions[\"action\"].fillna(\"show\")\n",
    "    sessions[\"action_type\"] = sessions[\"action_type\"].fillna(\"view\")\n",
    "    sessions[\"action_detail\"] = sessions[\"action_detail\"].fillna(\"view_search_results\")\n",
    "    \n",
    "    id_groupby = sessions.groupby(sessions[\"user_id\"]).agg(mode)\n",
    "    \n",
    "    device_type = []\n",
    "    action = []\n",
    "    action_type = []\n",
    "    action_detail = []\n",
    "    secs_elapsed = []\n",
    "\n",
    "    for i in range(len(id_groupby.index)):\n",
    "        device_type.append(id_groupby['device_type'][i][0])\n",
    "        action.append(id_groupby['action'][i][0])\n",
    "        action_type.append(id_groupby['action_type'][i][0])\n",
    "        action_detail.append(id_groupby['action_detail'][i][0])\n",
    "        secs_elapsed.append(id_groupby['secs_elapsed'][i][0])\n",
    "    \n",
    "    id_groupby_df = pd.DataFrame({\"id\":id_groupby.index ,\n",
    "                                  \"device_type\":device_type ,\n",
    "                                  \"action\":action,\n",
    "                                  \"action_type\":action_type,\n",
    "                                  \"action_detail\":action_detail,\n",
    "                                  \"secs_elapsed\":secs_elapsed\n",
    "                                  })\n",
    "    \n",
    "    ses = pd.read_csv(\"sessions.csv\")\n",
    "    ses = ses.filter(items=('user_id', 'secs_elapsed'))\n",
    "    \n",
    "    ses_groupby_sum = ses.groupby(\"user_id\").agg(np.sum)\n",
    "    ses_groupby_mean = ses.groupby(\"user_id\").agg(np.mean)\n",
    "    \n",
    "    merge_ses_groupby = pd.merge(ses_groupby_sum, ses_groupby_mean, left_index=True, right_index=True, how=\"left\")\n",
    "    merge_ses_groupby = merge_ses_groupby.rename(columns={'secs_elapsed_x': 'secs_sum', 'secs_elapsed_y': 'secs_mean'})\n",
    "    \n",
    "    merged_sessions = pd.merge(id_groupby_df, merge_ses_groupby, left_on=\"id\", right_index=True, how=\"left\")\n",
    "    \n",
    "    merged_sessions['secs_elapsed'] = merged_sessions['secs_elapsed'].astype(float)\n",
    "    \n",
    "    merged_sessions['secs_mean'] = merged_sessions['secs_mean'].fillna(0)\n",
    "    \n",
    "    merged_sessions.to_csv(\"merged_sessions.csv\", index=False)\n",
    "    \n",
    "    return merged_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sessions (remove word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_word():\n",
    "    \n",
    "    merged_sessions = pd.read_csv(\"merged_sessions.csv\")\n",
    "\n",
    "    def remove(word):\n",
    "        word = re.sub(\"''\", \"\", word)\n",
    "        word = re.sub(\"\\W\", \"\", word)\n",
    "        return word\n",
    "\n",
    "    merged_sessions[\"action\"] = merged_sessions[\"action\"].apply(remove)\n",
    "    merged_sessions[\"action_detail\"] = merged_sessions[\"action_detail\"].apply(remove)\n",
    "    merged_sessions[\"action_type\"] = merged_sessions[\"action_type\"].apply(remove)\n",
    "    merged_sessions[\"device_type\"] = merged_sessions[\"device_type\"].apply(remove)\n",
    "\n",
    "\n",
    "    merged_sessions[\"action_detail\"] = merged_sessions[\"action_detail\"].replace({\"['-unknown-']\":\"unknown\"})\n",
    "    merged_sessions[\"action_type\"] = merged_sessions[\"action_type\"].replace({\"['-unknown-']\":\"unknown\"})\n",
    "    merged_sessions[\"device_type\"] = merged_sessions[\"device_type\"].replace({\"['-unknown-']\":\"unknown\", \\\n",
    "                                            \"['Android App Unknown Phone/Tablet']\": \"Androd_unkown_phone\"})\n",
    "\n",
    "    merged_sessions = merged_sessions.to_csv(\"merged_sessions.csv\", index=False)\n",
    "    \n",
    "    return merged_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sessions (Action counts) - Last Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sessions_detail_add():\n",
    "\n",
    "    merged_sessions = pd.read_csv(\"merged_sessions.csv\")\n",
    "    sessions = pd.read_csv(\"sessions.csv\")\n",
    "\n",
    "    tmp = sessions.groupby([\"user_id\", \"action_type\"])[\"device_type\"].count().unstack().fillna(0)\n",
    "    sessions_at = pd.DataFrame(tmp)\n",
    "    sessions_at.rename(columns = lambda x : \"type__\" + x, inplace = True)\n",
    "\n",
    "    tmp = sessions.groupby([\"user_id\", \"action\"])[\"device_type\"].count().unstack().fillna(0)\n",
    "    sessions_a = pd.DataFrame(tmp)\n",
    "    sessions_a.rename(columns = lambda x : \"action__\" + x, inplace = True)\n",
    "\n",
    "    tmp = sessions.groupby([\"user_id\", \"action_detail\"])[\"device_type\"].count().unstack().fillna(0)\n",
    "    sessions_ad = pd.DataFrame(tmp)\n",
    "    sessions_ad.rename(columns = lambda x : \"detail__\" + x, inplace = True)\n",
    "\n",
    "    df_session_info = sessions_at.merge(sessions_a, how = \"outer\", left_index = True, right_index = True)\n",
    "    df_session_info = df_session_info.merge(sessions_ad, how = \"left\", left_index = True, right_index = True)\n",
    "\n",
    "    df_session_info.drop([\"type__-unknown-\", \"detail__-unknown-\"], axis = 1, inplace = True)\n",
    "    df_session_info = df_session_info.fillna(0)\n",
    "\n",
    "    last_merged_sessions = pd.merge(merged_sessions, df_session_info, left_on='id', right_index=True, how='left')\n",
    "\n",
    "    merged_sessions = last_merged_sessions.to_csv(\"merged_sessions.csv\", index=False)\n",
    "\n",
    "    return merged_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date setting - Base1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_age_set_data():\n",
    "    \n",
    "    check = pd.concat([train_users_2, test_users], ignore_index=True)\n",
    "    \n",
    "    check[\"first_affiliate_tracked\"] = check[\"first_affiliate_tracked\"].replace(np.nan, \"untracked\")\n",
    "\n",
    "    check[\"date_account_created\"] = pd.to_datetime(check[\"date_account_created\"], format = \"%Y-%m-%d\")\n",
    "    check[\"timestamp_first_active\"] = pd.to_datetime(check[\"timestamp_first_active\"], format=\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    s_lag = check[\"timestamp_first_active\"] - check[\"date_account_created\"]\n",
    "\n",
    "    check[\"lag_days\"] = s_lag.apply(lambda x : -1 * x.days)\n",
    "    check[\"lag_seconds\"] = s_lag.apply(lambda x : x.seconds)\n",
    "\n",
    "    s_all_check = (check['age'] < 120) & (check['gender'] != '-unknown-')\n",
    "\n",
    "    check['faithless_sign'] = s_all_check.apply(lambda x : 0 if x == True else 1)\n",
    "    \n",
    "    pre_age = check.drop(\"date_first_booking\",axis = 1)\n",
    "    \n",
    "    pre_age['date_account_created_y'] = pre_age[\"date_account_created\"].apply(lambda x : x.year)\n",
    "    pre_age['date_account_created_m'] = pre_age[\"date_account_created\"].apply(lambda x : x.month)\n",
    "    pre_age['date_account_created_d'] = pre_age[\"date_account_created\"].apply(lambda x : x.day)\n",
    "\n",
    "    pre_age['timestamp_first_active_y'] = pre_age[\"timestamp_first_active\"].apply(lambda x : x.year)\n",
    "    pre_age['timestamp_first_active_m'] = pre_age[\"timestamp_first_active\"].apply(lambda x : x.month)\n",
    "    pre_age['timestamp_first_active_d'] = pre_age[\"timestamp_first_active\"].apply(lambda x : x.day)\n",
    "\n",
    "    pre_age = pre_age.drop(\"date_account_created\" , axis=1)\n",
    "    pre_age = pre_age.drop(\"timestamp_first_active\" , axis=1)\n",
    "    \n",
    "    return check, pre_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date setting - Base2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_age_predict_data():\n",
    "    \n",
    "    pre_age['age'] = pre_age['age'].fillna(-1)\n",
    "    \n",
    "    pre_age_sub = pre_age.filter(items = ['age', 'country_destination','id'])\n",
    "    pre_age_dum = pre_age.filter(items = ['affiliate_channel', 'affiliate_provider',\n",
    "                                       'first_affiliate_tracked', 'first_browser', 'first_device_type',\n",
    "                                       'language', 'signup_app', 'signup_flow',\n",
    "                                       'signup_method', 'date_account_created_y', 'date_account_created_m',\n",
    "                                       'date_account_created_d', 'timestamp_first_active_y',\n",
    "                                       'timestamp_first_active_m', 'timestamp_first_active_d'])\n",
    "    \n",
    "    \n",
    "    pre_age_dum[['date_account_created_y', 'date_account_created_m', 'date_account_created_d', \\\n",
    "             'timestamp_first_active_y','timestamp_first_active_m', \\\n",
    "             'timestamp_first_active_d']] = pre_age_dum[['date_account_created_y', 'date_account_created_m', \\\n",
    "                                                         'date_account_created_d', 'timestamp_first_active_y',  \\\n",
    "                                                         'timestamp_first_active_m', \\\n",
    "                                                         'timestamp_first_active_d']].astype(str)\n",
    "    \n",
    "    \n",
    "    pre_age_dum = pd.get_dummies(pre_age_dum)\n",
    "    pre_age_dum_con = pd.concat([pre_age_dum, pre_age_sub], axis=1)\n",
    "    pre_age_dum_con[\"age\"] = pre_age_dum_con[\"age\"].replace(-1, np.nan)\n",
    "    \n",
    "    pre_age_mission = pre_age_dum_con[pre_age_dum_con[\"age\"].isna()].reset_index()\n",
    "    pre_age_train = pre_age_dum_con[pre_age_dum_con[\"age\"].notna()].reset_index()\n",
    "    \n",
    "    pre_age_mission_test = pre_age_mission.drop(\"index\", axis=1)\n",
    "    pre_age_train_test = pre_age_train.drop(\"index\", axis=1)\n",
    "    \n",
    "    pre_age_mission_test_drop = pre_age_mission_test.drop(['id', 'age', 'country_destination'], axis=1)\n",
    "    pre_age_train_test_drop = pre_age_train_test.drop(['id', 'age', 'country_destination'], axis=1)\n",
    "    \n",
    "    return pre_age_mission_test, pre_age_train_test, pre_age_mission, pre_age_train, \\\n",
    "            pre_age_mission_test_drop, pre_age_train_test_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_age_predict_data_cat():\n",
    "    \n",
    "    bins = [0, 15, 25, 35, 60, 9999]\n",
    "    labels = [\"미성년자\", \"청년\", \"중년\", \"장년\", \"노년\"]\n",
    "    cats = pd.cut(pre_age_train['age'], bins, labels=labels)\n",
    "    cats = pd.DataFrame(cats)\n",
    "    \n",
    "    return cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict gender data setting - Only gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gen_data = pd.read_csv(\"model_gen_lgb.csv\")\n",
    "\n",
    "def add_gender():\n",
    "    pre_gen_sub = pre_age.filter(items = ['age', 'country_destination', 'id', 'gender'])\n",
    "    pre_gen_dum = pre_age.filter(items = ['affiliate_channel', 'affiliate_provider',\n",
    "                                       'first_affiliate_tracked', 'first_browser', 'first_device_type',\n",
    "                                         'language', 'signup_app', 'signup_flow',\n",
    "                                       'signup_method', 'date_account_created_y', 'date_account_created_m',\n",
    "                                       'date_account_created_d', 'timestamp_first_active_y',\n",
    "                                       'timestamp_first_active_m', 'timestamp_first_active_d'])\n",
    "\n",
    "\n",
    "    pre_gen_dum = pd.get_dummies(pre_gen_dum)\n",
    "    pre_gen_dum_con = pd.concat([pre_gen_dum, pre_gen_sub], axis=1)\n",
    "    pre_gen_dum_con[\"gender\"] = pre_gen_dum_con[\"gender\"].replace(['-unknown-', 'OTHER'], np.nan)\n",
    "\n",
    "    pre_gen_mission = pre_gen_dum_con[pre_gen_dum_con[\"gender\"].isna()].reset_index()\n",
    "    pre_gen_train = pre_gen_dum_con[pre_gen_dum_con[\"gender\"].notna()].reset_index()\n",
    "\n",
    "    pre_gen_mission_test = pre_gen_mission.drop(\"index\", axis=1)\n",
    "    pre_gen_train_test = pre_gen_train.drop(\"index\", axis=1)\n",
    "\n",
    "    pre_gen_mission_test_drop = pre_gen_mission_test.drop(['id', 'age', 'country_destination', \"gender\"], axis=1)\n",
    "    pre_gen_train_test_drop = pre_gen_train_test.drop(['id', 'age', 'country_destination', \"gender\"], axis=1)\n",
    "\n",
    "    pre_gen_mission_test_la = pd.concat([pre_gen_mission_test, pred_gen_data], axis=1)\n",
    "    pre_gen_mission_test_la = pre_gen_mission_test_la.drop(\"gender\", axis=1)\n",
    "    pre_gen_mission_test_la = pre_gen_mission_test_la.rename(columns={\"0\": 'gender'})\n",
    "\n",
    "    last_gen_add = pd.concat([pre_gen_mission_test_la, pre_gen_train_test])\n",
    "\n",
    "    last_gen_add = last_gen_add.filter(items = [\"id\",'gender'])\n",
    "    \n",
    "    return last_gen_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday, Weekend, Day of week data setting - Only Holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def holiday():\n",
    "\n",
    "    def get_holidays(year):\n",
    "        response = requests.get(\"https://www.timeanddate.com/calendar/custom.html?year=\"+str(year)+\"\\\n",
    "                                &country=1&cols=3&df=1&hol=25\")\n",
    "        dom = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        trs = dom.select(\"table.cht.lpad tr\")\n",
    "\n",
    "        df = pd.DataFrame(columns=[\"date\", \"holiday\"])\n",
    "        for tr in trs:\n",
    "            datestr = tr.select_one(\"td:nth-of-type(1)\").text\n",
    "            date = datetime.strptime(\"{} {}\".format(year, datestr), '%Y %b %d')\n",
    "            holiday = tr.select_one(\"td:nth-of-type(2)\").text\n",
    "            df.loc[len(df)] = {\"date\" : date, \"holiday\": 1}\n",
    "        return df\n",
    "\n",
    "    holiday_ls = []\n",
    "    for year in range(2009, 2015):\n",
    "        df = get_holidays(year)\n",
    "        holiday_ls.append(df)\n",
    "        holiday_df = pd.concat(holiday_ls)\n",
    "\n",
    "    check = pd.concat([train_users_2, test_users], ignore_index=True)\n",
    "    check[\"timestamp_first_active\"] = check[\"timestamp_first_active\"].apply(lambda x : str(x)[:8])\n",
    "\n",
    "    pre_age_hol = check.filter(items=['id','timestamp_first_active'])\n",
    "\n",
    "    pre_age_hol['week'] = pd.to_datetime(check[\"timestamp_first_active\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "    pre_age_hol[\"week\"] = pre_age_hol['week'].dt.weekday\n",
    "    pre_age_hol[\"weekend\"] = pre_age_hol[\"week\"].apply(lambda x : 1 if x>=5 else 0)\n",
    "    pre_age_hol_dum = pd.get_dummies(pre_age_hol['week'])\n",
    "\n",
    "    hdfd = pd.concat([pre_age_hol,pre_age_hol_dum],axis=1)\n",
    "    hdfd = hdfd.drop(\"week\",axis=1)\n",
    "\n",
    "    hdfd = hdfd.rename(columns={0:\"mon\",1:\"tue\",2:\"wed\",3:\"thur\",4:\"fri\",5:\"sat\",6:\"sun\"})\n",
    "\n",
    "    hdfd['timestamp_first_active'] = pd.to_datetime(hdfd[\"timestamp_first_active\"])\n",
    "\n",
    "    add_hol = pd.merge(hdfd, holiday_df, left_on='timestamp_first_active', right_on=\"date\", how=\"left\")\n",
    "\n",
    "    add_hol = add_hol.drop([\"timestamp_first_active\",'date'],axis=1)\n",
    "    add_hol = add_hol.fillna(0)\n",
    "\n",
    "    return add_hol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict age data setting - Merge (age+gender+holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_age_data = pd.read_csv(\"model_age_lgb.csv\")\n",
    "# model_age_forest\n",
    "# model_age_xg\n",
    "# model_age_lgb\n",
    "\n",
    "def predict_age_add():\n",
    "    \n",
    "    pre_age_mission_test_la = pd.concat([pre_age_mission_test, pred_age_data], axis=1)\n",
    "    pre_age_mission_test_la = pre_age_mission_test_la.drop(\"age\", axis=1)\n",
    "#     pre_age_mission_test_la[\"0\"] = pre_age_mission_test_la[\"0\"].replace({'age1':25,\"age2\":29,\"age3\":34,\\\n",
    "#                                                                          \"age4\":40,\"age5\":55})\n",
    "\n",
    "    pre_age_mission_test_la[\"0\"] = pre_age_mission_test_la[\"0\"].replace({'미성년자':10,\"청년\":25,\"중년\":35,\\\n",
    "                                                                             \"장년\":45,\"노년\":60})\n",
    "                                                                     \n",
    "    pre_age_mission_test_la = pre_age_mission_test_la.rename(columns={\"0\": 'age'})\n",
    "    \n",
    "    pre_age_train_test_la = pre_age_train_test.drop(\"age\", axis=1)\n",
    "    pre_age_train_test_la['age'] = pre_age_train_test[\"age\"]\n",
    "    \n",
    "    last_age_add = pd.concat([pre_age_mission_test_la, pre_age_train_test_la])\n",
    "    \n",
    "    train_set = train_users_2['id']\n",
    "    train_set = pd.DataFrame(train_set)\n",
    "    test_set = test_users['id']\n",
    "    test_set = pd.DataFrame(test_set)\n",
    "    \n",
    "    last_gen_add_dum = pd.get_dummies(last_gen_add[\"gender\"])\n",
    "    last_gen_add_dum = pd.concat([last_gen_add['id'], last_gen_add_dum], axis=1)\n",
    "\n",
    "    last_train_data = pd.merge(train_set, last_age_add, on=\"id\", how=\"left\")\n",
    "    last_train_data = pd.merge(last_train_data, last_gen_add_dum, on=\"id\", how=\"left\")\n",
    "    \n",
    "    last_test_data = pd.merge(test_set, last_age_add, on=\"id\", how=\"left\")\n",
    "    last_test_data = pd.merge(last_test_data, last_gen_add_dum, on=\"id\", how=\"left\")\n",
    "    \n",
    "    last_train_data = pd.merge(last_train_data, add_hol, on='id', how=\"left\")\n",
    "    last_test_data = pd.merge(last_test_data, add_hol, on='id', how=\"left\")\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y_label = le.fit_transform(last_train_data[\"country_destination\"]) \n",
    "    \n",
    "    return last_train_data, last_test_data, y_label, le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data merge and make CSV - Last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_data_setting():\n",
    "    \n",
    "    merged_sessions = pd.read_csv(\"merged_sessions.csv\")\n",
    "    merged_sessions_dum = merged_sessions.drop(['id','secs_elapsed','secs_sum','secs_mean'], axis=1)\n",
    "    merged_sessions_dum = pd.get_dummies(merged_sessions_dum)\n",
    "    ses_dum = pd.concat([merged_sessions_dum,merged_sessions[['id','secs_elapsed','secs_sum','secs_mean']]],axis=1)\n",
    "    \n",
    "    last_train_data_add = pd.merge(last_train_data, ses_dum, on=\"id\", how=\"left\")\n",
    "    last_test_data_add = pd.merge(last_test_data, ses_dum, on=\"id\", how=\"left\")\n",
    "    \n",
    "    ## impute the missing value using median\n",
    "    impute_list = last_test_data_add.columns.tolist()\n",
    "    impute_list.remove(\"id\")\n",
    "    impute_list.remove(\"country_destination\")\n",
    "\n",
    "    imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "\n",
    "    last_train_data_add[impute_list] = imp.fit_transform(last_train_data_add[impute_list])\n",
    "    last_test_data_add[impute_list] = imp.fit_transform(last_test_data_add[impute_list])\n",
    "\n",
    "    last_train_data_add.to_csv(\"last_train_data_add.csv\", index=False)\n",
    "    last_test_data_add.to_csv(\"last_test_data_add.csv\", index=False)\n",
    "    \n",
    "    return last_train_data_add, last_test_data_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_setting():\n",
    "    last_train_data_add = pd.read_csv(\"last_train_data_add.csv\")\n",
    "    last_test_data_add = pd.read_csv(\"last_test_data_add.csv\")\n",
    "    \n",
    "    X = last_train_data_add\n",
    "    y = last_test_data_add\n",
    "    \n",
    "    model_lgb = lgb.LGBMClassifier(nthread=3, reg_alpha=1.0)\n",
    "    model_qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "    model_lda = LinearDiscriminantAnalysis(n_components=3, solver=\"svd\", store_covariance=True)\n",
    "    model_xg = XGBClassifier(nthread=3)\n",
    "    model_age_forest = ExtraTreesClassifier(n_estimators=250, random_state=0)\n",
    "    \n",
    "    return X, y, model_lgb, model_qda, model_lda, model_xg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Analysis Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_kaggle(df_train, df_test, model, path, user_id = \"id\", target = \"country_destination\"):\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    y_train = le.fit_transform(df_train[target])\n",
    "    X_train = df_train.drop([target, user_id], axis = 1)\n",
    "    \n",
    "    X_test_id = df_test[user_id]\n",
    "    X_test = df_test.drop([user_id, target], axis = 1)\n",
    "    \n",
    "    print(\"model fitting 시작\")\n",
    "    model = model.fit(X_train, y_train)\n",
    "    predic_proba = model.predict_proba(X_test)\n",
    "    print(\"model fitting 종료\")\n",
    "\n",
    "    df_submit = pd.DataFrame(columns=[\"id\", \"country\"])\n",
    "    ids = []\n",
    "    cts = []\n",
    "    for i in range(len(X_test_id)):\n",
    "        idx = X_test_id.iloc[i]\n",
    "        ids += [idx] * 5\n",
    "        cts += le.inverse_transform(np.argsort(predic_proba[i])[::-1])[:5].tolist()\n",
    "    df_submit[\"id\"] = ids\n",
    "    df_submit[\"country\"] = cts\n",
    "    df_submit.to_csv(path, index = False)\n",
    "    print(\"csv file 생성\")\n",
    "    !kaggle competitions submit -c airbnb-recruiting-new-user-bookings -f {path} -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "submit_kaggle(X, y, model_lgb, './submission/submit_xg.csv', \"id\", \"country_destination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Importance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_importance(model_lgb, figsize=(100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Importance Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_importance_feature():\n",
    "\n",
    "    importances = model_lgb.feature_importances_\n",
    "    importances = pd.DataFrame(importances, columns=[\"importance\"])\n",
    "\n",
    "    i_c = X.drop([\"id\", 'country_destination'],axis=1)\n",
    "    i_c = i_c.columns\n",
    "    i_c = pd.DataFrame(i_c, columns=[\"name\"])\n",
    "    f_i = pd.concat([i_c,importances],axis=1)\n",
    "\n",
    "    f_i_test3 = f_i[f_i['importance'] < 3]\n",
    "\n",
    "    f_i_test3_l = list(f_i_test3[\"name\"])\n",
    "\n",
    "    X_test_3 = X.drop(f_i_test3_l,axis=1)\n",
    "    y_test_3 = y.drop(f_i_test3_l, axis=1)\n",
    "    \n",
    "    return X_test_3, y_test_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb_i = lgb.LGBMClassifier(nthread=3, reg_alpha=1, n_estimators=100)\n",
    "model_qda_i = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "model_lda_i = LinearDiscriminantAnalysis(n_components=3, solver=\"svd\", store_covariance=True)\n",
    "model_xg_i = XGBClassifier(nthread=3)\n",
    "model_age_forest_i = ExtraTreesClassifier(n_estimators=250, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Analysis Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submit_kaggle(X_test_75, y_test_75, model_lgb_i, './submission/submit_xg.csv', \"id\", \"country_destination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Importance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_importance(### Classification Importance Check, figsize=(100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Point = 0.88425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y_label = le.fit_transform(X_test_75['country_destination']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(y_label, model_lgb_i.predict(X_test_75.drop([\"id\", \"country_destination\"], axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_label, \\\n",
    "                            model_lgb_i.predict(X_test_75.drop([\"id\", \"country_destination\"], axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Analysis Choice Make Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train = X_test_3.to_csv(\"last_train.csv\", index=False)\n",
    "last_test = y_test_3.to_csv(\"last_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0).fit(X_test_75.drop(['id', 'country_destination'],axis=1), y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_kaggle(X_test_3, y_test_3, tree1, './submission/submit_xg.csv', \"id\", \"country_destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_decision_tree(model):\n",
    "    dot_buf = io.StringIO() \n",
    "    export_graphviz(model, out_file=dot_buf, feature_names=X_test_75.columns.drop(['id', 'country_destination']))\n",
    "    graph = pydot.graph_from_dot_data(dot_buf.getvalue())[0] \n",
    "    image = graph.create_png()\n",
    "    return Image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_decision_tree(tree1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
