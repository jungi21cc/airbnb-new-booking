{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import clone\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_setting():\n",
    "    last_train_data_add = pd.read_csv(\"last_train.csv\")\n",
    "    last_test_data_add = pd.read_csv(\"last_test.csv\")\n",
    "    \n",
    "    X = last_train_data_add\n",
    "    y = last_test_data_add\n",
    "    \n",
    "#     clf1 = linear_model.LogisticRegression(n_jobs=-1)\n",
    "#     clf2 = RandomForestClassifier(n_jobs=-1)\n",
    "#     clf3 = ExtraTreesClassifier(n_jobs=-1)\n",
    "#     clf4 = xgb.XGBClassifier(nthread=3, n_jobs=-1)\n",
    "    clf5 = lgb.LGBMClassifier(nthread=3, n_jobs=-1, reg_alpha=1)\n",
    "#     eclf2 = VotingClassifier(estimators=[('log', clf1), ('rf', clf2), ('ex', clf3), ('xgb', clf4), ('lgb', clf5)], voting='soft', weights=[1,1,1,1,1])\n",
    "    \n",
    "    return X, y, clf5\n",
    "\n",
    "X, y, clf5  = pre_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_kaggle(df_train, df_test, model, user_id, target):\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "\n",
    "    y_train = le.fit_transform(df_train[target])\n",
    "    X_train = df_train.drop([target, user_id], axis = 1)\n",
    "    \n",
    "    X_test_id = df_test[user_id]\n",
    "    X_test = df_test.drop([target, user_id], axis = 1)\n",
    "    \n",
    "\n",
    "    print(\"model fitting 시작\")\n",
    "    \n",
    "    \n",
    "    model1 = model\n",
    "    parameters = {'learning_rate':[0.1,0.075], 'n_estimators':[75, 125], 'num_leaves':[31,50], 'subsample':[1,0.75] }\n",
    "    clf = GridSearchCV(n_jobs=-1, estimator=model1, param_grid=parameters).fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    predic_proba = clf.predict_proba(X_test)\n",
    "    \n",
    "    clf.best_score_()\n",
    "    \n",
    "    print(\"model fitting 종료\")\n",
    "\n",
    "    df_submit = pd.DataFrame(columns=[\"id\", \"country\"])\n",
    "    ids = []\n",
    "    cts = []\n",
    "    for i in range(len(X_test_id)):\n",
    "        idx = X_test_id.iloc[i]\n",
    "        ids += [idx] * 5\n",
    "        cts += le.inverse_transform(np.argsort(predic_proba[i])[::-1])[:5].tolist()\n",
    "    df_submit[\"id\"] = ids\n",
    "    df_submit[\"country\"] = cts\n",
    "    df_submit.to_csv('submit_xg.csv', index = False)\n",
    "    print(\"csv file 생성\")\n",
    "    !kaggle competitions submit -c airbnb-recruiting-new-user-bookings -f 'submit_xg.csv' -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_kaggle(X, y, clf5, \"id\", \"country_destination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting type\n",
    "#gbtree = 0.88388, 0.87941\n",
    "#dart = 0.88282, 0.87850\n",
    "#rf = error\n",
    "#goss = 0.87924, 0.87495\n",
    "\n",
    "## reg alpha, lambda\n",
    "#1, 0 = 0.88421, 0.87880\n",
    "#0.5, 0.5 = 0.88409, 0.87876\n",
    "#0.75, 0.25 = 0.88367, 0.87836\n",
    "\n",
    "## n_estimators\n",
    "#200 = 0.88418, 0.87937\n",
    "#300 = 0.88412, 0.87875\n",
    "#1000 = 0.88210, 0.87872\n",
    "\n",
    "### num_leaves\n",
    "#50 = 0.88384, 0.87988\n",
    "\n",
    "### learning rate\n",
    "#0.2 = 0.88339, 0.87920\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
